{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholas33/google-deepmind-gemma3-inference-nb153?scriptVersionId=227460281\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"ee37d757","metadata":{"execution":{"iopub.execute_input":"2025-03-13T19:57:02.831528Z","iopub.status.busy":"2025-03-13T19:57:02.831226Z","iopub.status.idle":"2025-03-13T19:57:40.935093Z","shell.execute_reply":"2025-03-13T19:57:40.933973Z"},"papermill":{"duration":38.109191,"end_time":"2025-03-13T19:57:40.937473","exception":false,"start_time":"2025-03-13T19:57:02.828282","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\r\n","  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /tmp/pip-req-build-8n0x0vri\r\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-8n0x0vri\r\n","  Running command git checkout -q 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\r\n","  Resolved https://github.com/huggingface/transformers to commit 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\r\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\r\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.29.0)\r\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\r\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (24.2)\r\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\r\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\r\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\r\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\r\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.4.5)\r\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\r\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.12.0)\r\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2025.0.1)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2022.0.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2.4.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\r\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.50.0.dev0) (2022.0.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.50.0.dev0) (1.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\r\n","Building wheels for collected packages: transformers\r\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10936429 sha256=6d9f5290ec3cafe3bc09ce2faf48f7543d0c5a47dd91ea90c3a4710fe659073c\r\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-1rk77xhs/wheels/c1/95/d1/7d800368ab25942bf88f88fe1716597fcc8d757043c9b48a2f\r\n","Successfully built transformers\r\n","Installing collected packages: transformers\r\n","  Attempting uninstall: transformers\r\n","    Found existing installation: transformers 4.47.0\r\n","    Uninstalling transformers-4.47.0:\r\n","      Successfully uninstalled transformers-4.47.0\r\n","Successfully installed transformers-4.50.0.dev0\r\n"]}],"source":["#/kaggle/input/gemma-3/transformers/gemma-3-1b-it/1\n","!pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"]},{"cell_type":"code","execution_count":2,"id":"15bc7a55","metadata":{"execution":{"iopub.execute_input":"2025-03-13T19:57:40.944723Z","iopub.status.busy":"2025-03-13T19:57:40.944446Z","iopub.status.idle":"2025-03-13T19:58:22.958849Z","shell.execute_reply":"2025-03-13T19:58:22.957988Z"},"papermill":{"duration":42.019825,"end_time":"2025-03-13T19:58:22.960632","exception":false,"start_time":"2025-03-13T19:57:40.940807","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Device in use: cuda\n"]}],"source":["import kagglehub\n","import torch \n","from transformers import AutoTokenizer \n","from transformers.models.gemma3 import Gemma3ForCausalLM\n","\n","#Model Setup: Downloads the Gemma 3 (1 billion parameter, instruction-tuned version) directly from Kaggle Hub.\n","GEMMA_PATH = \"/kaggle/input/gemma-3/transformers/gemma-3-1b-it/1\"\n","\n","#Model Initialization: Prepares the Gemma 3 tokenizer and model for inference, + CUDA + confirming GPU availability \n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n","print(f\"Device in use: {device}\")\n","tokenizer = AutoTokenizer.from_pretrained(GEMMA_PATH)\n","model = Gemma3ForCausalLM.from_pretrained(GEMMA_PATH).to(device)"]},{"cell_type":"code","execution_count":3,"id":"c9b2b419","metadata":{"execution":{"iopub.execute_input":"2025-03-13T19:58:22.96782Z","iopub.status.busy":"2025-03-13T19:58:22.967259Z","iopub.status.idle":"2025-03-13T19:58:22.972836Z","shell.execute_reply":"2025-03-13T19:58:22.972016Z"},"papermill":{"duration":0.010862,"end_time":"2025-03-13T19:58:22.974535","exception":false,"start_time":"2025-03-13T19:58:22.963673","status":"completed"},"tags":[]},"outputs":[],"source":["def create_prompt(user_question):\n","    return f\"\"\"<start_of_turn>user\\n{user_question}<end_of_turn>\\n<start_of_turn>model\"\"\"\n","\n","\n","generation_config = {\n","    \"max_new_tokens\": 1024, \n","    \"temperature\": 0.5, \n","    \"do_sample\": True, #greedy decoding to make it fastere do_sample = false \n","    \"top_p\": 0.7, \n","    \"eos_token_id\": tokenizer.eos_token_id,\n","    \"pad_token_id\": tokenizer.eos_token_id\n","}\n","\n","def ask_gemma(question): \n","    prompt = create_prompt(question)\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)  \n","    outputs = model.generate(**inputs, **generation_config)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    print(response)"]},{"cell_type":"code","execution_count":4,"id":"9198c116","metadata":{"execution":{"iopub.execute_input":"2025-03-13T19:58:22.981045Z","iopub.status.busy":"2025-03-13T19:58:22.980769Z","iopub.status.idle":"2025-03-13T19:59:26.450009Z","shell.execute_reply":"2025-03-13T19:59:26.448952Z"},"papermill":{"duration":63.476731,"end_time":"2025-03-13T19:59:26.454217","exception":false,"start_time":"2025-03-13T19:58:22.977486","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["user\n","What can Gemma 3 do for a voice assistant?\n","model Technically, Gemma 3 isn't a voice assistant *per se*. It's a large language model – a text-based AI. However, it *could* be integrated into a voice assistant in a few ways, leveraging its text-based capabilities. Here's a breakdown of what it could do, categorized by complexity and potential:\n","\n","**1. Basic Command & Response (Easiest - Requires Integration)**\n","\n","* **Voice-Activated Question Answering:** This is the most straightforward. You could say, \"Gemma, what's the weather like?\" and it would respond with the current weather information.\n","* **Simple Task Completion:**  \"Gemma, set an alarm for 7 AM.\" – It could handle this.\n","* **Text-Based Commands:**  \"Gemma, play my favorite playlist.\" – It could access your music service and play the playlist.\n","* **Information Retrieval:** \"Gemma, tell me about the history of Rome.\" – It could pull information from its knowledge base.\n","\n","**2. Intermediate - Leveraging Context & Dialogue (More Complex)**\n","\n","* **Contextual Conversation:**  This is where it gets interesting. You could build a system where Gemma 3 remembers previous turns in the conversation.  For example:\n","    * **User:** \"I need to book a flight to Paris.\"\n","    * **Gemma:** \"Okay, what dates are you looking at?\"\n","    * **User:** \"Next weekend.\"\n","    * **Gemma:** \"Let me check flights for next weekend...  I found a flight to Paris on Friday.  Would you like me to book it?\"\n","* **Role-Playing:**  You could instruct Gemma to take on a specific persona (e.g., \"Act as a travel agent\").\n","* **Creative Text Generation (with constraints):** You could ask it to write a poem about a specific topic, but it would need to be guided with prompts and constraints. \"Write a haiku about autumn leaves.\"\n","* **Summarization:** \"Summarize this article for me: [paste article text]\"\n","\n","**3. Advanced -  More Complex Integration (Requires Significant Development)**\n","\n","* **Voice-Controlled Content Creation:**  This is a more ambitious idea. You could use voice commands to generate text content (e.g., a blog post, email, or script) and then have Gemma 3 refine and improve it.\n","* **Sentiment Analysis & Response:**  You could ask Gemma to analyze the sentiment of a user's voice and respond accordingly (e.g., \"You sound frustrated.  Let me see if I can help.\").\n","* **Personalized Recommendations:** Based on conversation history, Gemma could offer tailored recommendations (e.g., \"Based on what you've been reading, you might enjoy this book.\").\n","* **Complex Task Orchestration:**  Combining multiple actions – e.g., \"Book a flight to Paris, then find a hotel, and send me a confirmation email.\"\n","\n","\n","**Important Considerations & Limitations:**\n","\n","* **No Native Voice Input:** Gemma 3 doesn't have a microphone directly. It relies on voice input through a connected device (like a smart speaker).\n","* **API Access:**  To integrate with a voice assistant, you'd need to use the Gemma API (or a similar API) and build a system to send voice commands to the API and receive responses.\n","* **Latency:**  Voice assistants often have latency, so the response time from Gemma 3 needs to be carefully considered.\n","\n","\n","**Resources for Learning More:**\n","\n","* **Gemma Documentation:** [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\n","* **Google AI Studio:** [https://ai.google.dev/studio/](https://ai.google.dev/studio/) -  A platform for experimenting with models like Gemma.\n","\n","\n","To help me give you even more tailored advice, could you tell me:\n","\n","*   What kind of voice assistant are you envisioning? (e.g., Alexa, Google Assistant, a custom voice assistant)\n","*   What is the primary goal of this voice assistant? (e.g., general information, task management, entertainment)elbenesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupportesupport\n"]}],"source":["user_question = \"What can Gemma 3 do for a voice assistant?\"\n","ask_gemma(user_question)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"isSourceIdPinned":true,"modelId":222398,"modelInstanceId":239467,"sourceId":282742,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":150.04093,"end_time":"2025-03-13T19:59:29.658165","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-13T19:56:59.617235","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}